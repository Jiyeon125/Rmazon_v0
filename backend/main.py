from fastapi import FastAPI, UploadFile, File, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import pandas as pd
from pandas import DataFrame
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import Ridge
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction import text
import os
import shutil
from typing import List, Optional, Dict, Any
import numpy as np
import joblib
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from scipy.sparse import csr_matrix
from collections import Counter

# --- Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ ÌÇ§ÏõåÎìú ÏÑ∏Ìä∏ ---
# ÏÉÅÌíà ÏÑ§Î™Ö Î∂ÑÏÑùÏùÑ ÌÜµÌï¥ ÏÉùÏÑ±Îêú Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ Ï£ºÏöî ÌÇ§ÏõåÎìú(cursor Ï∂îÏ≤ú)
KEYWORD_SETS = {
    'Car&Motorbike | CarAccessories | InteriorAccessories': ['reffair', 'ax30', 'filter', 'purification', 'car', 'hepa', 'efficient', 'h13', 'makes', 'comes', 'tested', 'reliable', 'performance', 'many', 'inside'],
    'Computers&Accessories | Accessories&Peripherals | Adapters': ['plug', 'charging', 'type-c', 'usb-c', 'used', 'transfer', 'note', 'transmission', 'allows', 'laptops', 'peripherals', 'into', 'usb-a', 'supports', 'built-in'],
    'Computers&Accessories | Accessories&Peripherals | Audio&VideoAccessories': ['windows', 'laptop', 'video', 'speaker', '5mm', 'powered', 'calls', 'clip', 'sound', 'audio', 'camera', 'webcam', 'either', 'control', 'source'],
    'Computers&Accessories | Accessories&Peripherals | Cables&Accessories': ['charging', 'charge', 'fast', 'speed', 'iphone', 'power', 'durable', 'transfer', 'type-c', 'ipad', 'charger', 'supports', 'braided', 'nylon', 'micro'],
    'Computers&Accessories | Accessories&Peripherals | HardDiskBags': ['hard', 'case', 'drive', 'mesh', 'cables', 'bag', 'water', 'elastic', 'pocket', 'flash', 'drives', 'keeps', 'disk', 'band', 'securely'],
    'Computers&Accessories | Accessories&Peripherals | HardDriveAccessories': ['laptop', 'drive', '5mm', 'hard', 'hdd', 'sata', 'new', 'laptops', 'replace', 'current', 'channels', 'switch', 'help', 'improve', 'try'],
    'Computers&Accessories | Accessories&Peripherals | Keyboards,Mice&InputDevices': ['mouse', 'wireless', 'keyboard', 'battery', 'optical', 'windows', 'pad', 'receiver', 'life', 'click', 'dpi', 'technology', 'tablet', 'writing', 'button'],
    'Computers&Accessories | Accessories&Peripherals | LaptopAccessories': ['laptop', 'stand', 'table', 'desk', 'foldable', 'bed', 'work', 'laptops', 'carry', 'cover', 'ipad', 'protection', 'height', 'legs', 'ergonomic'],
    'Computers&Accessories | Accessories&Peripherals | PCGamingPeripherals': ['gaming', 'mouse', 'dpi', 'comes', 'windows', 'buttons', 'rgb', 'led', 'switch', 'light', 'game', 'dedicated', 'equipped', 'experience', 'gamers'],
    'Computers&Accessories | Accessories&Peripherals | TabletAccessories': ['ipad', 'generation', '7th', '8th', 'case', '9th', 'designed', 'fit', 'model', 'clarity', 'transparency', 'fingerprint', 'protects', 'new', 'specifically'],
    'Computers&Accessories | Accessories&Peripherals | USBGadgets': ['light', 'power', 'led', 'lighting', 'rated', 'car', 'voltage', 'standard', 'small', 'into', 'energy', 'night', 'room', 'side', 'falls'],
    'Computers&Accessories | Accessories&Peripherals | USBHubs': ['hub', 'usb-a', 'connect', 'transfer', 'card', 'mport', 'gives', 'working', 'speed', 'macbook', 'comes', 'plug', 'play', 'type-c', '5gbps'],
    'Computers&Accessories | Accessories&Peripherals | UninterruptedPowerSupplies': ['load', 'mains', 'battery', 'power', 'voltage', 'time', 'generator', 'compact', 'line', 'interactive', 'ups', 'capacity', '360watts', '600va', 'frequency'],
    'Computers&Accessories | Components | InternalHardDrives': ['laptop', 'hdd', '5mm', 'hard', 'drive', 'channels', 'switch', 'help', 'improve', 'try', 'move', 'read', 'sata', 'ssd', 'include'],
    'Computers&Accessories | Components | InternalSolidStateDrives': ['write', 'drive', 'ssd', 'nand', 'speeds', 'read', 'micron', 'crucial', 'bx500', 'power', 'advanced', 'than', 'performance', 'storage', '240gb'],
    'Computers&Accessories | Components | Memory': ['crucial', 'system', 'ease', 'configuration', 'improve', 'responsiveness', 'run', 'apps', 'faster', 'multitask', 'extended', 'timings', '22-22-22', 'install', 'computer'],
    'Computers&Accessories | ExternalDevices&DataStorage | ExternalHardDisks': ['drive', 'enclosure', 'hard', 'windows', 'protection', 'hardware', 'hdd', 'digital', 'password', 'mac', 'reformatting', 'systems', 'ssd', 'capacity', 'interface'],
    'Computers&Accessories | ExternalDevices&DataStorage | PenDrives&StorageCards': ['drive', 'card', 'memory', 'speed', 'read', 'microsdxc', 'transfer', 'class', 'storage', 'sandisk', 'adapter', 'uhs-i', 'photos', 'ideal', 'apps'],
    'Computers&Accessories | NetworkingDevices | DataCards&Dongles': ['connect', 'unlocked', 'lte', 'network', 'speed', 'jiofi', 'hotspot', 'sim', 'jdr740', 'wifi', '4g', 'supports', 'internet', 'wireless', 'upload'],
    'Computers&Accessories | NetworkingDevices | NetworkAdapters': ['wifi', 'wireless', 'adapter', 'speed', 'band', 'dual', 'supports', 'windows', 'range', 'security', 'speeds', 'linux', 'nano', 'high-gain', 'wpa-psk'],
    'Computers&Accessories | NetworkingDevices | Routers': ['router', 'dual', 'band', 'speed', 'wireless', 'wifi', 'tenda', 'gigabit', 'parental', 'control', 'ports', 'connect', 'internet', 'beaming', 'technology'],
    'Electronics | Cameras&Photography | Accessories': ['tripod', 'phone', 'mobile', 'light', 'camera', 'mini', 'angle', 'cameras', 'stand', 'dslr', 'button', 'holder', 'cleaning', 'height', 'screw'],
    'Electronics | Cameras&Photography | Flashes': ['light', 'ring', 'led', 'lighting', 'brightness', 'live', 'easily', 'different', 'tripod', 'phone', 'holder', 'power', 'suitable', 'mode', 'adjust'],
    'Electronics | Cameras&Photography | SecurityCameras': ['camera', 'video', 'smart', 'storage', '1080p', 'advanced', 'night', 'vision', 'detection', 'light', 'google', 'alexa', 'security', 'full', 'cloud'],
    'Electronics | Cameras&Photography | VideoCameras': ['video', 'web', 'camera', 'experience', 'supports', '640x480', 'pixels', 'comes', 'videos', 'uploads', 'webcam', 'tripod', 'plug', 'noise', 'w100'],
    'Electronics | GeneralPurposeBatteries&BatteryChargers': ['batteries', 'lithium', 'used', 'duracell', 'coin', 'advanced', 'battery', 'eneloop', 'charger', 'charge', 'remotes', 'panasonic', 'chargers', 'suitable', 'keyfobs'],
    'Electronics | Headphones,Earbuds&Accessories | Headphones': ['sound', 'earbuds', 'hours', 'experience', 'time', 'drivers', 'bass', 'calls', 'music', 'voice', 'audio', 'bluetooth', 'ear', 'mic', 'charging'],
    'Electronics | HomeAudio | Speakers': ['speaker', 'bluetooth', 'aux', 'time', 'wireless', 'volume', 'battery', 'dual', 'charging', 'hours', 'offers', 'sound', 'playback', 'comes', 'audio'],
    'Electronics | HomeTheater,TV&Video | Accessories': ['remote', 'hdmi', 'fire', 'control', 'audio', 'before', 'led', 'please', 'smart', 'supports', 'stick', 'video', 'inches', 'batteries', 'durable'],
    'Electronics | HomeTheater,TV&Video | Projectors': ['projector', 'display', 'pixel', 'projectors', 'projection', 'screen', 'life', 'hours', 'size', 'led', 'resolution', 'large', 'hdmi', 'clear', 'light'],
    'Electronics | HomeTheater,TV&Video | Televisions': ['connect', 'installation', 'sound', 'information', 'resolution', 'smart', 'display', 'hdmi', 'top', 'provided', 'panel', 'dolby', 'hard', 'drives', 'rate'],
    'Electronics | Mobiles&Accessories | MobileAccessories': ['charging', 'phone', 'ipad', 'charge', 'iphone', 'power', 'fast', 'charger', 'mobile', 'protector', 'stand', 'protection', 'cables', 'selfie', 'screen'],
    'Electronics | Mobiles&Accessories | Smartphones&BasicMobiles': ['camera', 'display', 'battery', 'processor', 'dual', 'sim', '2mp', 'memory', 'ram', 'front', 'storage', 'nano', '8mp', 'resolution', '50mp'],
    'Electronics | PowerAccessories | SurgeProtectors': ['power', 'through', 'maximum', 'spike', 'current', 'amps', 'grounds', '3-line', 'protection', 'sockets', 'delivers', '5-metre', 'heavyduty', 'cables', 'superior'],
    'Electronics | WearableTechnology | SmartWatches': ['watch', 'smartwatch', 'display', 'sports', 'health', 'bluetooth', 'modes', 'calling', 'touch', 'faces', 'fire-boltt', 'smart', 'rate', 'calls', 'heart'],
    'Health&PersonalCare | HomeMedicalSupplies&Equipment | HealthMonitors': ['weight', 'function', 'comes', 'weighing', 'ingredients', 'measurement', 'bowl', 'scale', 'units', 'battery', 'off', 'tare', 'allows', 'measure', 'after'],
    'Home&Kitchen | Kitchen&Dining | KitchenTools': ['chopper', 'unique', 'string', 'function', 'chop', 'vegetables', 'fruits', 'ease', 'package', 'contents', '1-piece', 'handy', 'blade', 'centimeters', 'eco-friendly'],
    'Home&Kitchen | Kitchen&HomeAppliances | SmallKitchenAppliances': ['steel', 'stainless', 'power', 'jar', 'motor', 'food', 'electric', 'water', 'blender', 'kettle', 'time', 'kitchen', 'body', 'off', 'make'],
    'Home&Kitchen | Kitchen&HomeAppliances | Vacuum,Cleaning&Ironing': ['lint', 'dust', 'power', 'vacuum', 'cleaning', 'cord', 'cleaner', 'clean', 'clothes', 'hair', 'fabric', 'remover', 'suction', 'powerful', 'fabrics'],
    'Home&Kitchen | Kitchen&HomeAppliances | WaterPurifiers&Accessories': ['water', 'filter', 'purifier', 'purification', 'installation', 'technology', 'capacity', 'tds', 'filters', 'removes', 'membrane', 'taste', 'used', 'copper', 'germkill'],
    'MusicalInstruments | Microphones | Condenser': ['microphone', 'dslr', 'smartphone', 'off', 'jack', 'audio', 'omni', 'designed', 'camcorders', 'recorders', 'switch', 'slide', 'only', 'laptop', 'recording']
}

# --- Pydantic Î™®Îç∏ Ï†ïÏùò ---
# API ÏöîÏ≤≠/ÏùëÎãµÏùò Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞Î•º Ï†ïÏùòÌïòÏó¨ Ïú†Ìö®ÏÑ± Í≤ÄÏÇ¨ Î∞è Î¨∏ÏÑúÌôîÎ•º ÏûêÎèôÌôîÌï©ÎãàÎã§.
class Keyword(BaseModel):
    """Î¶¨Î∑∞ Î∂ÑÏÑù Í≤∞Í≥ºÏóêÏÑú ÏÇ¨Ïö©Îê† ÌÇ§ÏõåÎìúÏôÄ ÎπàÎèÑÏàò Î™®Îç∏"""
    word: str
    count: int

class PredictionRequest(BaseModel):
    """ÌåêÎß§ ÏßÄÌëú ÏòàÏ∏° ÏöîÏ≤≠ Î™®Îç∏"""
    price: float
    category: str

class PredictionResponse(BaseModel):
    """ÌåêÎß§ ÏßÄÌëú ÏòàÏ∏° Í≤∞Í≥º ÏùëÎãµ Î™®Îç∏"""
    predicted_star: float
    predicted_review_count: float
    price_percentile: float
    review_count_percentile: float
    rating_percentile: float

class SimilarityRequest(BaseModel):
    """Ïú†ÏÇ¨ÎèÑ Í≤ÄÏÉâ ÏöîÏ≤≠ Î™®Îç∏"""
    description: str
    price: float
    discount_percentage: float
    category: str

class Product(BaseModel):
    """Í∏∞Î≥∏ ÏÉÅÌíà Ï†ïÎ≥¥ Î™®Îç∏"""
    product_id: str
    product_name: str

class ReviewAnalysis(BaseModel):
    """Î¶¨Î∑∞ Î∂ÑÏÑù Í≤∞Í≥º Î™®Îç∏"""
    positive_percentage: float
    negative_percentage: float
    neutral_percentage: float
    top_positive_keywords: List[str]
    top_negative_keywords: List[str]

class ProductInfo(BaseModel):
    """ÏÉÅÌíàÏùò Ï¢ÖÌï© Ï†ïÎ≥¥ Î™®Îç∏"""
    product_id: str
    product_name: str
    category: str
    price: float
    review_count: int
    review_analysis: ReviewAnalysis

class SimilarProduct(ProductInfo):
    """Ïú†ÏÇ¨ÎèÑ Ï†êÏàòÍ∞Ä Ìè¨Ìï®Îêú ÏÉÅÌíà Ï†ïÎ≥¥ Î™®Îç∏ (ÌòÑÏû¨Îäî ÏßÅÏ†ë ÏÇ¨Ïö©ÎêòÏßÄ ÏïäÏùå)"""
    similarity: float

class SimilarityResult(BaseModel):
    """Ïú†ÏÇ¨ÎèÑ Í≤ÄÏÉâ Í≤∞Í≥ºÎ°ú Î∞òÌôòÎê† Í∞Å ÏÉÅÌíàÏùò ÏÉÅÏÑ∏ Ï†ïÎ≥¥ Î™®Îç∏"""
    product_id: str
    product_name: str
    category: str
    similarity: float # ÏµúÏ¢Ö Ïú†ÏÇ¨ÎèÑ Ï†êÏàò (TF-IDF + ÌÇ§ÏõåÎìú Ï†êÏàò)
    discounted_price: float
    rating: float
    rating_count: int
    review_analysis: ReviewAnalysis

class PriceRangeResponse(BaseModel):
    """Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ Í∞ÄÍ≤© Î≤îÏúÑ ÏùëÎãµ Î™®Îç∏"""
    min_price: float
    max_price: float

class DistributionBin(BaseModel):
    """Î∂ÑÌè¨ÎèÑ Ï∞®Ìä∏Ïùò Í∞Å ÎßâÎåÄÎ•º ÎÇòÌÉÄÎÇ¥Îäî Î™®Îç∏"""
    name: str
    count: int

class CategoryStatsResponse(BaseModel):
    """Ïπ¥ÌÖåÍ≥†Î¶¨ ÌÜµÍ≥Ñ Ï†ïÎ≥¥ ÏùëÎãµ Î™®Îç∏"""
    min_price: float
    max_price: float
    min_review_count: float
    max_review_count: float
    price_distribution: List[DistributionBin]
    review_count_distribution: List[DistributionBin]
    rating_distribution: List[DistributionBin]

# --- FastAPI Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò ÏÑ§Ï†ï ---
app = FastAPI()

# CORS ÎØ∏Îì§Ïõ®Ïñ¥ Ï∂îÍ∞Ä: Next.js Ïï±(http://localhost:3000)ÏóêÏÑúÏùò ÏöîÏ≤≠ÏùÑ ÌóàÏö©Ìï©ÎãàÎã§.
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Ï†ÑÏó≠ Î≥ÄÏàò: Î™®Îç∏, Îç∞Ïù¥ÌÑ∞, Ï†ÑÏ≤òÎ¶¨Í∏∞ ---
ml_pipe = None
review_count_pipe = None # Î¶¨Î∑∞ Ïàò ÏòàÏ∏° Î™®Îç∏
hierarchical_categories_data = {} # Í≥ÑÏ∏µÏ†Å Ïπ¥ÌÖåÍ≥†Î¶¨ Îç∞Ïù¥ÌÑ∞
tfidf_vectorizer = None
tfidf_matrix = None
df_products: pd.DataFrame = pd.DataFrame() # ÏÉÅÌíà Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Î∞è Ïú†ÏÇ¨ÎèÑ Î∂ÑÏÑùÏö©
df_reviews: pd.DataFrame = pd.DataFrame() # ÏÉÅÌíàÎ≥Ñ Í∞úÎ≥Ñ Î¶¨Î∑∞ Ï†ÄÏû•Ïö©
DATA_FILE_PATH = os.path.join("data", "cleaned_amazon_0519.csv")

# --- ÌïµÏã¨ Î°úÏßÅ: Îç∞Ïù¥ÌÑ∞ Î°úÎî© Î∞è Î™®Îç∏ ÌïôÏäµ ---
def load_data_and_train_models():
    """
    ÏÑúÎ≤Ñ ÏãúÏûë Ïãú Ïã§ÌñâÎêòÎäî ÌïµÏã¨ Ìï®Ïàò.
    1. CSV Îç∞Ïù¥ÌÑ∞ ÌååÏùºÏùÑ ÏùΩÏñ¥Îì§ÏûÖÎãàÎã§.
    2. Îç∞Ïù¥ÌÑ∞Î•º Ï†ïÏ†úÌïòÍ≥† Í∏∞Î≥∏ ÌÉÄÏûÖÏùÑ Î≥ÄÌôòÌï©ÎãàÎã§.
    3. 'review_content'Ïóê ÏâºÌëúÎ°ú Ìï©Ï≥êÏßÑ Î¶¨Î∑∞Îì§ÏùÑ Î∂ÑÎ¶¨ÌïòÏó¨ ÏÉÅÌíàÎ≥Ñ Í∞úÎ≥Ñ Î¶¨Î∑∞(df_reviews)Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
       Ïù¥ Í≥ºÏ†ïÏóêÏÑú Îçî Ï†ïÌôïÌïú Î∂ÑÏÑùÏùÑ ÏúÑÌï¥ Î¶¨Î∑∞ Ï†úÎ™©('review_title')Í≥º ÎÇ¥Ïö©('review_content')ÏùÑ Í≤∞Ìï©Ìï©ÎãàÎã§.
    4. ÏÉÅÌíà Î©îÌÉÄÎç∞Ïù¥ÌÑ∞(df_products)Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
    5. df_productsÎ•º Í∏∞Î∞òÏúºÎ°ú 3Í∞ÄÏßÄ Î®∏Ïã†Îü¨Îãù Î™®Îç∏ÏùÑ ÌïôÏäµÌï©ÎãàÎã§:
        - Î≥ÑÏ†ê ÏòàÏ∏° Î™®Îç∏ (ml_pipe)
        - Î¶¨Î∑∞ Ïàò ÏòàÏ∏° Î™®Îç∏ (review_count_pipe)
        - ÏÉÅÌíà ÏÑ§Î™Ö Í∏∞Î∞ò TF-IDF Î™®Îç∏ (tfidf_vectorizer, tfidf_matrix)
    6. ÌîÑÎ°†Ìä∏ÏóîÎìúÏóêÏÑú ÏÇ¨Ïö©Ìï† Í≥ÑÏ∏µÏ†Å Ïπ¥ÌÖåÍ≥†Î¶¨ Îç∞Ïù¥ÌÑ∞Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
    """
    global ml_pipe, review_count_pipe, tfidf_vectorizer, tfidf_matrix, df_products, df_reviews, hierarchical_categories_data
    
    if not os.path.exists(DATA_FILE_PATH):
        print(f"‚ö†Ô∏è Îç∞Ïù¥ÌÑ∞ ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§: {DATA_FILE_PATH}")
        df_products, df_reviews = pd.DataFrame(), pd.DataFrame()
        return

    df_raw = pd.read_csv(DATA_FILE_PATH)
    
    required_columns = ['product_id', 'product_name', 'about_product', 'review_title', 'review_content', 'discounted_price', 'rating_count', 'category_cleaned', 'rating']
    if any(col not in df_raw.columns for col in required_columns):
        missing_cols = [col for col in required_columns if col not in df_raw.columns]
        raise ValueError(f"ÌïÑÏàò Ïª¨Îüº Ï§ë ÏùºÎ∂ÄÍ∞Ä ÎàÑÎùΩÎêòÏóàÏäµÎãàÎã§: {', '.join(missing_cols)}")

    # --- 1. Í∏∞Î≥∏ ÌÅ¥Î¶¨Îãù Î∞è ÌÉÄÏûÖ Î≥ÄÌôò ---
    df_raw['about_product'] = df_raw['about_product'].fillna('')
    df_raw['review_title'] = df_raw['review_title'].fillna('')
    df_raw['review_content'] = df_raw['review_content'].fillna('')
    for col in ['discounted_price', 'rating_count', 'rating']:
        df_raw[col] = pd.to_numeric(df_raw[col], errors='coerce')
    df_raw.dropna(subset=['product_id', 'discounted_price', 'rating_count', 'rating', 'category_cleaned'], inplace=True)

    # --- 2. Î¶¨Î∑∞ Î∂ÑÎ¶¨ Î∞è df_reviews ÏÉùÏÑ± (Ï†úÎ™© + ÎÇ¥Ïö© Í≤∞Ìï©) ---
    # CSVÏùò Ìïú ÏÖÄÏóê Î™®Îì† Î¶¨Î∑∞Í∞Ä ÏâºÌëúÎ°ú Ìï©Ï≥êÏ†∏ ÏûàÎäî Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÍ∏∞ ÏúÑÌï¥,
    # Í∞Å ÏÉÅÌíàÏùò Î™®Îì† Î¶¨Î∑∞Î•º Í∞úÎ≥Ñ ÌñâÏúºÎ°ú Î∂ÑÎ¶¨ÌïòÏó¨ Î≥ÑÎèÑÏùò DataFrame(df_reviews)ÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.
    reviews_list = []
    for _, row in df_raw.iterrows():
        contents = [c.strip() for c in str(row['review_content']).split(',') if c.strip()]
        title = str(row['review_title']).strip()
        for content_part in contents:
            full_review_text = (title + ' ' + content_part).strip()
            reviews_list.append({'product_id': row['product_id'], 'review_text': full_review_text})
    df_reviews = pd.DataFrame(reviews_list)
    
    # --- 3. Ïú†ÏÇ¨ÎèÑ Î∂ÑÏÑù Î∞è ÏòàÏ∏° Î™®Îç∏ ÌïôÏäµÏö© df_products ÏÉùÏÑ± ---
    # Î¶¨Î∑∞ Îç∞Ïù¥ÌÑ∞Î•º Ï†úÏô∏Ìïú ÏàúÏàò ÏÉÅÌíà Ï†ïÎ≥¥(Î©îÌÉÄÎç∞Ïù¥ÌÑ∞)ÎßåÏúºÎ°ú DataFrameÏùÑ Íµ¨ÏÑ±ÌïòÍ≥†, ÏÉÅÌíà ID Í∏∞Ï§Ä Ï§ëÎ≥µÏùÑ Ï†úÍ±∞Ìï©ÎãàÎã§.
    df_meta_cols = ['product_id', 'product_name', 'about_product', 'category_cleaned', 'discounted_price', 'rating_count', 'rating']
    df_products = df_raw[df_meta_cols].drop_duplicates(subset=['product_id']).copy()
    df_products.dropna(subset=['discounted_price', 'rating_count', 'rating', 'category_cleaned'], inplace=True)

    # --- 4. Î™®Îç∏ ÌïôÏäµ ---
    # Í∞ÄÍ≤©(numeric)Í≥º Ïπ¥ÌÖåÍ≥†Î¶¨(categorical) Ï†ïÎ≥¥Î•º Í∏∞Î∞òÏúºÎ°ú Î≥ÑÏ†êÍ≥º Î¶¨Î∑∞ ÏàòÎ•º ÏòàÏ∏°ÌïòÎäî Î™®Îç∏ÏùÑ ÎßåÎì≠ÎãàÎã§.
    numeric_features = ['discounted_price']
    categorical_features = ['category_cleaned']
    X_features = df_products[numeric_features + categorical_features]
    preprocessor = ColumnTransformer(transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)])
    
    # Î™®Îç∏ 1: Î≥ÑÏ†ê(rating) ÏòàÏ∏°
    y_rating = df_products['rating']
    ml_pipe = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', Ridge(alpha=1.0))])
    ml_pipe.fit(X_features, y_rating)
    print("‚úÖ Rating Prediction model training complete!")

    # Î™®Îç∏ 2: Î¶¨Î∑∞ Ïàò(rating_count) ÏòàÏ∏°
    y_review_count = df_products['rating_count']
    review_count_pipe = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', Ridge(alpha=1.0))])
    review_count_pipe.fit(X_features, y_review_count)
    print("‚úÖ Review Count Prediction model training complete!")

    # Î™®Îç∏ 3: TF-IDF Î™®Îç∏ ÌïôÏäµ (Ïú†ÏÇ¨ÎèÑ Î∂ÑÏÑùÏö©)
    tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
    tfidf_matrix = tfidf_vectorizer.fit_transform(df_products['about_product'])
    print("‚úÖ TF-IDF model (based on product description) training complete!")
    
    # --- 5. Í≥ÑÏ∏µÏ†Å Ïπ¥ÌÖåÍ≥†Î¶¨ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± ---
    # ÌîÑÎ°†Ìä∏ÏóîÎìúÏóêÏÑú ÎèôÏ†Å Ïπ¥ÌÖåÍ≥†Î¶¨ ÏÑ†ÌÉù UIÎ•º Íµ¨ÌòÑÌïòÍ∏∞ ÏúÑÌï¥
    temp_hierarchical_data = {}
    for cat_string in df_products['category_cleaned'].unique():
        parts = cat_string.split(' | ')
        current_level = temp_hierarchical_data
        for part in parts:
            if part not in current_level:
                current_level[part] = {}
            current_level = current_level[part]
    hierarchical_categories_data = temp_hierarchical_data
    print("‚úÖ Hierarchical category data created!")
    print(f"üìà Total {len(df_products)} unique products and {len(df_reviews)} individual reviews loaded.")
    print(f"‚≠ê Rating range found in data: {df_products['rating'].min()} ~ {df_products['rating'].max()}")


# --- ÏÑúÎ≤Ñ ÏãúÏûë Ïãú Ïã§ÌñâÎê† Î°úÏßÅ ---
@app.on_event("startup")
def startup_event():
    try:
        load_data_and_train_models()
    except Exception as e:
        print(f"üö® ÏÑúÎ≤Ñ ÏãúÏûë Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}")


# --- API ÏóîÎìúÌè¨Ïù∏Ìä∏ Ï†ïÏùò ---
@app.get("/")
def read_root():
    """API ÏÑúÎ≤ÑÏùò Î£®Ìä∏ ÏóîÎìúÌè¨Ïù∏Ìä∏. ÏÑúÎ≤ÑÍ∞Ä Ïã§Ìñâ Ï§ëÏù∏ÏßÄ ÌôïÏù∏ÌïòÎäî Îç∞ ÏÇ¨Ïö©Îê©ÎãàÎã§."""
    return {"message": "Rmazon predictor and similarity API is running!"}

@app.get("/categories", response_model=List[str])
def get_categories():
    """Îç∞Ïù¥ÌÑ∞ÏÖãÏóê ÏûàÎäî Î™®Îì† ÏµúÏÉÅÏúÑ Ïπ¥ÌÖåÍ≥†Î¶¨ Î™©Î°ùÏùÑ Î∞òÌôòÌï©ÎãàÎã§."""
    if not hierarchical_categories_data:
        raise HTTPException(status_code=503, detail="Ïπ¥ÌÖåÍ≥†Î¶¨ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏïÑÏßÅ Î°úÎìúÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
    return list(hierarchical_categories_data.keys())

@app.get("/hierarchical-categories", response_model=Dict)
def get_hierarchical_categories():
    """Ï†ÑÏ≤¥ Ïπ¥ÌÖåÍ≥†Î¶¨ Íµ¨Ï°∞Î•º Í≥ÑÏ∏µÏ†Å(JSON) ÌòïÌÉúÎ°ú Î∞òÌôòÌï©ÎãàÎã§."""
    if not hierarchical_categories_data:
        raise HTTPException(status_code=503, detail="Ïπ¥ÌÖåÍ≥†Î¶¨ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏïÑÏßÅ Î°úÎìúÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
    return hierarchical_categories_data

@app.get("/product-count", response_model=int)
def get_product_count(category: str = Query(..., description="ÏÉÅÌíà ÏàòÎ•º Ï°∞ÌöåÌï† Ï†ÑÏ≤¥ Ïπ¥ÌÖåÍ≥†Î¶¨ Í≤ΩÎ°ú")):
    """ÏÑ†ÌÉùÎêú ÏµúÏ¢Ö Ïπ¥ÌÖåÍ≥†Î¶¨Ïóê Ìï¥ÎãπÌïòÎäî ÏÉÅÌíàÏùò Ï¥ù Í∞úÏàòÎ•º Î∞òÌôòÌï©ÎãàÎã§."""
    if df_products.empty:
        return 0
    return int(df_products[df_products['category_cleaned'] == category].shape[0])

@app.get("/products", response_model=List[Product])
def get_products(category: Optional[str] = Query(None)):
    """ÌäπÏ†ï Ïπ¥ÌÖåÍ≥†Î¶¨Ïóê ÏÜçÌïú ÏÉÅÌíà Î™©Î°ùÏùÑ Î∞òÌôòÌï©ÎãàÎã§."""
    if df_products.empty:
        return []
    target_df = df_products
    if category:
        target_df = df_products[df_products['category_cleaned'] == category]
    return target_df[['product_id', 'product_name']].to_dict(orient='records')

def advanced_review_analysis(reviews: List[str]) -> Dict[str, Any]:
    """
    VADERÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Î¶¨Î∑∞ Î™©Î°ùÏùò Í∏ç/Î∂ÄÏ†ï/Ï§ëÎ¶Ω ÎπÑÏú®ÏùÑ Î∂ÑÏÑùÌïòÍ≥†,
    Í∏çÏ†ï/Î∂ÄÏ†ï Î¶¨Î∑∞ÏóêÏÑú Í∞ÄÏû• ÎπàÎèÑÍ∞Ä ÎÜíÏùÄ ÌÇ§ÏõåÎìúÎ•º Ï∂îÏ∂úÌï©ÎãàÎã§.
    """
    if not reviews:
        return {"positive_percentage": 0, "negative_percentage": 0, "neutral_percentage": 100, "top_positive_keywords": [], "top_negative_keywords": []}
    
    analyzer = SentimentIntensityAnalyzer()
    positive_reviews_text, negative_reviews_text = [], []
    pos_count, neg_count, neu_count = 0, 0, 0

    for review in reviews:
        score = analyzer.polarity_scores(review)
        if score['compound'] >= 0.05:
            positive_reviews_text.append(review)
            pos_count += 1
        elif score['compound'] <= -0.05:
            negative_reviews_text.append(review)
            neg_count += 1
        else:
            neu_count += 1

    total = len(reviews)
    positive_percentage = (pos_count / total) * 100
    negative_percentage = (neg_count / total) * 100
    neutral_percentage = (neu_count / total) * 100

    custom_stop_words = text.ENGLISH_STOP_WORDS.union(['product', 'good', 'great', 'bad', 'price', 'quality', 'item', 'like', 'just', 'really', 'very', 'amazon', 'nice', 'best', 'time', 'use', 'working', 'not', 'don', 'doesn', 'is', 'are'])

    def extract_top_keywords(texts: List[str], stop_words, top_n=5) -> List[str]:
        if not texts: return []
        words = ' '.join(texts).lower().split()
        filtered_words = [word for word in words if word.isalpha() and word not in stop_words]
        return [word for word, count in Counter(filtered_words).most_common(top_n)]

    positive_keywords = extract_top_keywords(positive_reviews_text, custom_stop_words)
    negative_keywords = extract_top_keywords(negative_reviews_text, custom_stop_words)

    return {
        'positive_percentage': round(positive_percentage, 2),
        'negative_percentage': round(negative_percentage, 2),
        'neutral_percentage': round(neutral_percentage, 2),
        'top_positive_keywords': positive_keywords,
        'top_negative_keywords': negative_keywords
    }

@app.get("/category-price-range", response_model=PriceRangeResponse)
def get_category_price_range(category: str = Query(...)):
    """ÌäπÏ†ï Ïπ¥ÌÖåÍ≥†Î¶¨Ïùò ÏµúÏÜå/ÏµúÎåÄ Í∞ÄÍ≤©ÏùÑ Î∞òÌôòÌï©ÎãàÎã§."""
    if df_products.empty:
        raise HTTPException(status_code=404, detail="ÏÉÅÌíà Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
    filtered_df = df_products[df_products['category_cleaned'] == category]
    if filtered_df.empty:
        return PriceRangeResponse(min_price=0.0, max_price=0.0)
    min_price = filtered_df['discounted_price'].min()
    max_price = filtered_df['discounted_price'].max()
    return PriceRangeResponse(min_price=float(min_price), max_price=float(max_price))

@app.get("/category-stats", response_model=CategoryStatsResponse)
def get_category_stats(category: str = Query(..., description="ÌÜµÍ≥Ñ Ï†ïÎ≥¥Î•º Ï°∞ÌöåÌï† Ïπ¥ÌÖåÍ≥†Î¶¨")):
    """ÌäπÏ†ï Ïπ¥ÌÖåÍ≥†Î¶¨Ïùò Í∞ÄÍ≤©, Î¶¨Î∑∞ Ïàò, Î≥ÑÏ†ê Î∂ÑÌè¨ Îì± Ï¢ÖÌï©Ï†ÅÏù∏ ÌÜµÍ≥Ñ Ï†ïÎ≥¥Î•º Î∞òÌôòÌï©ÎãàÎã§."""
    if df_products.empty:
        raise HTTPException(status_code=503, detail="ÏÉÅÌíà Îç∞Ïù¥ÌÑ∞Í∞Ä ÏïÑÏßÅ Î°úÎìúÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
    
    category_df = df_products[df_products['category_cleaned'] == category]
    if category_df.empty:
        return CategoryStatsResponse(min_price=0, max_price=0, min_review_count=0, max_review_count=0, price_distribution=[], review_count_distribution=[], rating_distribution=[])

    def create_histogram(data: pd.Series, bins=10) -> List[DistributionBin]:
        if data.empty: return []
        counts, bin_edges = np.histogram(data.dropna(), bins=bins)
        return [DistributionBin(name=f"{bin_edges[i]:.0f}-{bin_edges[i+1]:.0f}", count=int(counts[i])) for i in range(len(counts))]

    def process_rating_distribution(data: pd.Series) -> List[DistributionBin]:
        if data.empty: return []
        rating_counts = (data.dropna() / 0.5).round() * 0.5
        rating_distribution = rating_counts.value_counts().sort_index()
        return [DistributionBin(name=f"{rating:.1f}", count=int(count)) for rating, count in rating_distribution.items()]

    price_dist = create_histogram(category_df['discounted_price'])
    review_count_dist = create_histogram(category_df['rating_count'])
    rating_dist = process_rating_distribution(category_df['rating'])

    return CategoryStatsResponse(
        min_price=float(category_df['discounted_price'].min()),
        max_price=float(category_df['discounted_price'].max()),
        min_review_count=float(category_df['rating_count'].min()),
        max_review_count=float(category_df['rating_count'].max()),
        price_distribution=price_dist,
        review_count_distribution=review_count_dist,
        rating_distribution=rating_dist
    )

@app.post("/search-similarity", response_model=List[SimilarityResult])
def search_similarity(request: SimilarityRequest):
    """
    ÏûÖÎ†•Îêú ÏÉÅÌíà ÏÑ§Î™ÖÍ≥º Í∞ÄÏû• Ïú†ÏÇ¨Ìïú ÏÉÅÌíàÎì§ÏùÑ TF-IDF Î∞è ÌÇ§ÏõåÎìú Ï†êÏàòÎ•º Í∏∞Î∞òÏúºÎ°ú Ï∞æÏïÑÏÑú Î∞òÌôòÌï©ÎãàÎã§.
    """
    global tfidf_vectorizer, tfidf_matrix, df_products
    if tfidf_vectorizer is None or tfidf_matrix is None or df_products.empty:
        raise HTTPException(status_code=503, detail="ÏÑúÎ≤ÑÍ∞Ä ÏïÑÏßÅ Ï§ÄÎπÑÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
    
    input_vector = tfidf_vectorizer.transform([request.description])
    cosine_similarities = cosine_similarity(input_vector, tfidf_matrix).flatten()
    similar_indices = cosine_similarities.argsort()[-20:][::-1]
    
    KEYWORD_BOOST_FACTOR = 0.05
    category_keywords = KEYWORD_SETS.get(request.category, [])
    
    results = []
    for i in similar_indices:
        base_similarity = cosine_similarities[i]
        keyword_score = sum(1 for keyword in category_keywords if keyword in df_products.iloc[i]['about_product'].lower())
        final_score = base_similarity + (keyword_score * KEYWORD_BOOST_FACTOR)
        product_info = df_products.iloc[i].to_dict()
        product_info['similarity'] = final_score
        results.append(product_info)

    results.sort(key=lambda x: x['similarity'], reverse=True)

    final_results = []
    for item in results[:10]: # ÏÉÅÏúÑ 10Í∞úÎßå Î∞òÌôò
        product_id = item.get('product_id')
        product_reviews = df_reviews[df_reviews['product_id'] == product_id]['review_text'].tolist() if product_id else []
        review_analysis_result = advanced_review_analysis(product_reviews)
        final_results.append(SimilarityResult(
            product_id=item.get('product_id', 'N/A'),
            product_name=item.get('product_name', 'N/A'),
            category=item.get('category_cleaned', 'N/A'),
            similarity=item.get('similarity', 0.0),
            discounted_price=item.get('discounted_price', 0.0),
            rating=item.get('rating', 0.0),
            rating_count=int(item.get('rating_count', 0)),
            review_analysis=ReviewAnalysis(**review_analysis_result)
        ))
    return final_results

@app.post("/predict", response_model=PredictionResponse)
def predict_star_rating(request: PredictionRequest):
    """
    ÏûÖÎ†•Îêú Í∞ÄÍ≤©Í≥º Ïπ¥ÌÖåÍ≥†Î¶¨Î•º Î∞îÌÉïÏúºÎ°ú ÏòàÏÉÅ Î≥ÑÏ†êÍ≥º Î¶¨Î∑∞ ÏàòÎ•º ÏòàÏ∏°Ìï©ÎãàÎã§.
    ÎòêÌïú ÏûÖÎ†•Îêú Í∞ÄÍ≤©Ïù¥ Ìï¥Îãπ Ïπ¥ÌÖåÍ≥†Î¶¨ ÎÇ¥ÏóêÏÑú Ïñ¥Îäê Ï†ïÎèÑ ÏàòÏ§ÄÏù∏ÏßÄ Î∞±Î∂ÑÏúÑ Ï†ïÎ≥¥Î•º Ìï®Íªò Ï†úÍ≥µÌï©ÎãàÎã§.
    """
    if ml_pipe is None or df_products.empty or review_count_pipe is None:
        raise HTTPException(status_code=503, detail="Î™®Îç∏Ïù¥ ÏïÑÏßÅ Ï§ÄÎπÑÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
    
    try:
        input_data = pd.DataFrame([[request.price, request.category]], columns=['discounted_price', 'category_cleaned'])
        predicted_star = ml_pipe.predict(input_data)[0]
        predicted_review_count = review_count_pipe.predict(input_data)[0]

        category_df = df_products[df_products['category_cleaned'] == request.category]
        
        def calculate_percentile(series: pd.Series, score: float) -> float:
            if series.empty: return 0.0
            from scipy.stats import percentileofscore
            return float(percentileofscore(series.dropna(), score, kind='weak'))

        price_percentile = calculate_percentile(category_df['discounted_price'], request.price)
        review_count_percentile = calculate_percentile(category_df['rating_count'], float(predicted_review_count))
        rating_percentile = calculate_percentile(category_df['rating'], float(predicted_star))

        return PredictionResponse(
            predicted_star=round(float(predicted_star), 2),
            predicted_review_count=round(float(predicted_review_count), 0),
            price_percentile=round(price_percentile, 2),
            review_count_percentile=round(review_count_percentile, 2),
            rating_percentile=round(rating_percentile, 2)
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ÏòàÏ∏° Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}") 